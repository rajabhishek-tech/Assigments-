{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2.  predicting turbine energy yield (TEY) using ambient variables as features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "dataset= pd.read_csv('gas_turbines.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(50,15))\n",
    "sns.boxplot(data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AT', 'AP', 'AH', 'AFDP', 'GTEP', 'TIT', 'TAT', 'TEY', 'CDP', 'CO', 'NOX']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = list(dataset.columns)\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  \n",
       "0      82.722  \n",
       "1      82.776  \n",
       "2      82.468  \n",
       "3      82.670  \n",
       "4      82.311  \n",
       "...       ...  \n",
       "15034  79.559  \n",
       "15035  79.917  \n",
       "15036  90.912  \n",
       "15037  93.227  \n",
       "15038  92.498  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=dataset.drop(['TEY'],axis=1)\n",
    "X=df\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        114.70\n",
       "1        114.72\n",
       "2        114.71\n",
       "3        114.72\n",
       "4        114.72\n",
       "          ...  \n",
       "15034    111.61\n",
       "15035    111.78\n",
       "15036    110.19\n",
       "15037    110.74\n",
       "15038    111.58\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=dataset['TEY']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=10, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -2202291.8186 - accuracy: 0.0000e+00 - val_loss: -34105932.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -71096992.1546 - accuracy: 0.0000e+00 - val_loss: -231757952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -330797578.0059 - accuracy: 0.0000e+00 - val_loss: -664510976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -844399749.0109 - accuracy: 0.0000e+00 - val_loss: -1367266304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1637136556.0198 - accuracy: 0.0000e+00 - val_loss: -2370500864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: -2758111638.4539 - accuracy: 0.0000e+00 - val_loss: -3699835136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -4212234522.6402 - accuracy: 0.0000e+00 - val_loss: -5388966912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6033796720.1427 - accuracy: 0.0000e+00 - val_loss: -7467135488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: -8273528843.1635 - accuracy: 0.0000e+00 - val_loss: -9963461632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10980174707.9485 - accuracy: 0.0000e+00 - val_loss: -12908614656.0000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24c610c4550>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 1ms/step - loss: -13147474944.0000 - accuracy: 0.0000e+00\n",
      "accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS TUNING\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardization\n",
    "a = StandardScaler()\n",
    "a.fit(X)\n",
    "X_standardized = a.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.169680e-15</td>\n",
       "      <td>-1.925280e-14</td>\n",
       "      <td>2.007245e-16</td>\n",
       "      <td>3.810001e-16</td>\n",
       "      <td>1.111478e-16</td>\n",
       "      <td>-2.324212e-15</td>\n",
       "      <td>1.744899e-15</td>\n",
       "      <td>2.542166e-16</td>\n",
       "      <td>1.959261e-17</td>\n",
       "      <td>-3.646853e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.276462e+00</td>\n",
       "      <td>-4.266288e+00</td>\n",
       "      <td>-3.536594e+00</td>\n",
       "      <td>-2.779497e+00</td>\n",
       "      <td>-1.806771e+00</td>\n",
       "      <td>-5.021933e+00</td>\n",
       "      <td>-4.188141e+00</td>\n",
       "      <td>-1.992416e+00</td>\n",
       "      <td>-8.874862e-01</td>\n",
       "      <td>-3.861033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.392292e-01</td>\n",
       "      <td>-6.706510e-01</td>\n",
       "      <td>-6.796337e-01</td>\n",
       "      <td>-6.266930e-01</td>\n",
       "      <td>-5.091458e-01</td>\n",
       "      <td>-2.540512e-01</td>\n",
       "      <td>-4.101146e-01</td>\n",
       "      <td>-4.354335e-01</td>\n",
       "      <td>-5.015202e-01</td>\n",
       "      <td>-6.578107e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.566605e-02</td>\n",
       "      <td>-6.227861e-02</td>\n",
       "      <td>2.277844e-01</td>\n",
       "      <td>-1.854065e-02</td>\n",
       "      <td>-8.075681e-02</td>\n",
       "      <td>2.965544e-01</td>\n",
       "      <td>5.712570e-01</td>\n",
       "      <td>-7.011925e-02</td>\n",
       "      <td>-2.620452e-01</td>\n",
       "      <td>-1.518527e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.051309e-01</td>\n",
       "      <td>5.772924e-01</td>\n",
       "      <td>7.916582e-01</td>\n",
       "      <td>4.612196e-01</td>\n",
       "      <td>4.228638e-01</td>\n",
       "      <td>7.382490e-01</td>\n",
       "      <td>5.928675e-01</td>\n",
       "      <td>4.311680e-01</td>\n",
       "      <td>8.455882e-02</td>\n",
       "      <td>5.486567e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.266234e+00</td>\n",
       "      <td>3.275970e+00</td>\n",
       "      <td>1.528011e+00</td>\n",
       "      <td>4.486233e+00</td>\n",
       "      <td>2.871006e+00</td>\n",
       "      <td>1.028678e+00</td>\n",
       "      <td>6.627839e-01</td>\n",
       "      <td>2.700105e+00</td>\n",
       "      <td>1.895949e+01</td>\n",
       "      <td>4.937717e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04   \n",
       "mean  -1.169680e-15 -1.925280e-14  2.007245e-16  3.810001e-16  1.111478e-16   \n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00   \n",
       "min   -2.276462e+00 -4.266288e+00 -3.536594e+00 -2.779497e+00 -1.806771e+00   \n",
       "25%   -8.392292e-01 -6.706510e-01 -6.796337e-01 -6.266930e-01 -5.091458e-01   \n",
       "50%    5.566605e-02 -6.227861e-02  2.277844e-01 -1.854065e-02 -8.075681e-02   \n",
       "75%    8.051309e-01  5.772924e-01  7.916582e-01  4.612196e-01  4.228638e-01   \n",
       "max    2.266234e+00  3.275970e+00  1.528011e+00  4.486233e+00  2.871006e+00   \n",
       "\n",
       "                  5             6             7             8             9  \n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  \n",
       "mean  -2.324212e-15  1.744899e-15  2.542166e-16  1.959261e-17 -3.646853e-17  \n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  \n",
       "min   -5.021933e+00 -4.188141e+00 -1.992416e+00 -8.874862e-01 -3.861033e+00  \n",
       "25%   -2.540512e-01 -4.101146e-01 -4.354335e-01 -5.015202e-01 -6.578107e-01  \n",
       "50%    2.965544e-01  5.712570e-01 -7.011925e-02 -2.620452e-01 -1.518527e-01  \n",
       "75%    7.382490e-01  5.928675e-01  4.311680e-01  8.455882e-02  5.486567e-01  \n",
       "max    1.028678e+00  6.627839e-01  2.700105e+00  1.895949e+01  4.937717e+00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tuning of Hyperparameters :- Batch Size and Epochs\n",
    "# Importing the necessary packages\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=10, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/1] END ..................batch_size=10, epochs=10; total time=  15.1s\n",
      "[CV 2/5; 1/1] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/1] END ..................batch_size=10, epochs=10; total time=  11.2s\n",
      "[CV 3/5; 1/1] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/1] END ..................batch_size=10, epochs=10; total time=  10.8s\n",
      "[CV 4/5; 1/1] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/1] END ..................batch_size=10, epochs=10; total time=  11.4s\n",
      "[CV 5/5; 1/1] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/1] END ..................batch_size=10, epochs=10; total time=  11.4s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10]\n",
    "epochs = [10]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 1/5; 1/9] END .....dropout_rate=0.0, learning_rate=0.001; total time=   4.3s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 2/5; 1/9] END .....dropout_rate=0.0, learning_rate=0.001; total time=   3.8s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 3/5; 1/9] END .....dropout_rate=0.0, learning_rate=0.001; total time=   4.3s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 4/5; 1/9] END .....dropout_rate=0.0, learning_rate=0.001; total time=   4.0s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 5/5; 1/9] END .....dropout_rate=0.0, learning_rate=0.001; total time=   4.4s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 1/5; 2/9] END ......dropout_rate=0.0, learning_rate=0.01; total time=   5.6s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 2/5; 2/9] END ......dropout_rate=0.0, learning_rate=0.01; total time=   7.2s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 3/5; 2/9] END ......dropout_rate=0.0, learning_rate=0.01; total time=   4.5s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 4/5; 2/9] END ......dropout_rate=0.0, learning_rate=0.01; total time=   4.5s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 5/5; 2/9] END ......dropout_rate=0.0, learning_rate=0.01; total time=   4.3s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 1/5; 3/9] END .......dropout_rate=0.0, learning_rate=0.1; total time=   4.8s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 2/5; 3/9] END .......dropout_rate=0.0, learning_rate=0.1; total time=   4.2s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 3/5; 3/9] END .......dropout_rate=0.0, learning_rate=0.1; total time=   4.3s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 4/5; 3/9] END .......dropout_rate=0.0, learning_rate=0.1; total time=   4.2s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 5/5; 3/9] END .......dropout_rate=0.0, learning_rate=0.1; total time=   4.2s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 1/5; 4/9] END .....dropout_rate=0.1, learning_rate=0.001; total time=   3.6s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 2/5; 4/9] END .....dropout_rate=0.1, learning_rate=0.001; total time=   3.4s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 3/5; 4/9] END .....dropout_rate=0.1, learning_rate=0.001; total time=   3.9s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 4/5; 4/9] END .....dropout_rate=0.1, learning_rate=0.001; total time=   5.9s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 5/5; 4/9] END .....dropout_rate=0.1, learning_rate=0.001; total time=   6.3s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 1/5; 5/9] END ......dropout_rate=0.1, learning_rate=0.01; total time=   4.8s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 2/5; 5/9] END ......dropout_rate=0.1, learning_rate=0.01; total time=   4.2s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 3/5; 5/9] END ......dropout_rate=0.1, learning_rate=0.01; total time=   4.7s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 4/5; 5/9] END ......dropout_rate=0.1, learning_rate=0.01; total time=   3.9s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 5/5; 5/9] END ......dropout_rate=0.1, learning_rate=0.01; total time=   4.8s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 1/5; 6/9] END .......dropout_rate=0.1, learning_rate=0.1; total time=   4.7s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 2/5; 6/9] END .......dropout_rate=0.1, learning_rate=0.1; total time=   4.0s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 3/5; 6/9] END .......dropout_rate=0.1, learning_rate=0.1; total time=   4.5s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 4/5; 6/9] END .......dropout_rate=0.1, learning_rate=0.1; total time=   4.1s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 5/5; 6/9] END .......dropout_rate=0.1, learning_rate=0.1; total time=   4.1s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 1/5; 7/9] END .....dropout_rate=0.2, learning_rate=0.001; total time=   4.4s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 2/5; 7/9] END .....dropout_rate=0.2, learning_rate=0.001; total time=   7.4s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 3/5; 7/9] END .....dropout_rate=0.2, learning_rate=0.001; total time=   4.7s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 4/5; 7/9] END .....dropout_rate=0.2, learning_rate=0.001; total time=   3.5s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 5/5; 7/9] END .....dropout_rate=0.2, learning_rate=0.001; total time=   3.8s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 1/5; 8/9] END ......dropout_rate=0.2, learning_rate=0.01; total time=   3.9s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 2/5; 8/9] END ......dropout_rate=0.2, learning_rate=0.01; total time=   3.4s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 3/5; 8/9] END ......dropout_rate=0.2, learning_rate=0.01; total time=   3.4s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 4/5; 8/9] END ......dropout_rate=0.2, learning_rate=0.01; total time=   3.8s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 5/5; 8/9] END ......dropout_rate=0.2, learning_rate=0.01; total time=   4.3s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 1/5; 9/9] END .......dropout_rate=0.2, learning_rate=0.1; total time=   3.8s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 2/5; 9/9] END .......dropout_rate=0.2, learning_rate=0.1; total time=   3.9s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 3/5; 9/9] END .......dropout_rate=0.2, learning_rate=0.1; total time=   4.3s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 4/5; 9/9] END .......dropout_rate=0.2, learning_rate=0.1; total time=   4.3s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 5/5; 9/9] END .......dropout_rate=0.2, learning_rate=0.1; total time=   4.3s\n"
     ]
    }
   ],
   "source": [
    "#### Tuning of Hyperparameters:- Learning rate and Drop out rate\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 10,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 10,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform; total time=   4.0s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform; total time=   4.2s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform; total time=   4.3s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform; total time=   4.2s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform; total time=   4.8s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 1/5; 2/12] END .activation_function=softmax, init=normal; total time=   4.9s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 2/5; 2/12] END .activation_function=softmax, init=normal; total time=   5.6s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 3/5; 2/12] END .activation_function=softmax, init=normal; total time=   4.9s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 4/5; 2/12] END .activation_function=softmax, init=normal; total time=   5.0s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 5/5; 2/12] END .activation_function=softmax, init=normal; total time=   4.6s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 1/5; 3/12] END ...activation_function=softmax, init=zero; total time=   6.5s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 2/5; 3/12] END ...activation_function=softmax, init=zero; total time=   6.2s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 3/5; 3/12] END ...activation_function=softmax, init=zero; total time=   4.2s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 4/5; 3/12] END ...activation_function=softmax, init=zero; total time=   4.0s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 5/5; 3/12] END ...activation_function=softmax, init=zero; total time=   4.4s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 1/5; 4/12] END ...activation_function=relu, init=uniform; total time=   4.2s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 2/5; 4/12] END ...activation_function=relu, init=uniform; total time=   3.9s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 3/5; 4/12] END ...activation_function=relu, init=uniform; total time=   3.9s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 4/5; 4/12] END ...activation_function=relu, init=uniform; total time=   4.2s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 5/5; 4/12] END ...activation_function=relu, init=uniform; total time=   4.1s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 1/5; 5/12] END ....activation_function=relu, init=normal; total time=   4.4s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 2/5; 5/12] END ....activation_function=relu, init=normal; total time=   4.2s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 3/5; 5/12] END ....activation_function=relu, init=normal; total time=   4.9s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 4/5; 5/12] END ....activation_function=relu, init=normal; total time=   6.1s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 5/5; 5/12] END ....activation_function=relu, init=normal; total time=   5.8s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 1/5; 6/12] END ......activation_function=relu, init=zero; total time=   4.9s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 2/5; 6/12] END ......activation_function=relu, init=zero; total time=   4.1s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 3/5; 6/12] END ......activation_function=relu, init=zero; total time=   3.2s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 4/5; 6/12] END ......activation_function=relu, init=zero; total time=   3.3s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 5/5; 6/12] END ......activation_function=relu, init=zero; total time=   3.6s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 1/5; 7/12] END ...activation_function=tanh, init=uniform; total time=   3.8s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 2/5; 7/12] END ...activation_function=tanh, init=uniform; total time=   3.5s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 3/5; 7/12] END ...activation_function=tanh, init=uniform; total time=   3.4s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 4/5; 7/12] END ...activation_function=tanh, init=uniform; total time=   3.5s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 5/5; 7/12] END ...activation_function=tanh, init=uniform; total time=   3.7s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 1/5; 8/12] END ....activation_function=tanh, init=normal; total time=   3.3s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 2/5; 8/12] END ....activation_function=tanh, init=normal; total time=   3.2s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 3/5; 8/12] END ....activation_function=tanh, init=normal; total time=   4.2s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 4/5; 8/12] END ....activation_function=tanh, init=normal; total time=   6.3s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 5/5; 8/12] END ....activation_function=tanh, init=normal; total time=   3.8s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 1/5; 9/12] END ......activation_function=tanh, init=zero; total time=   3.2s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 2/5; 9/12] END ......activation_function=tanh, init=zero; total time=   3.4s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 3/5; 9/12] END ......activation_function=tanh, init=zero; total time=   3.7s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 4/5; 9/12] END ......activation_function=tanh, init=zero; total time=   3.3s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 5/5; 9/12] END ......activation_function=tanh, init=zero; total time=   3.2s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform; total time=   3.3s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform; total time=   3.8s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform; total time=   3.3s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform; total time=   3.3s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform; total time=   3.3s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/12] END .activation_function=linear, init=normal; total time=   3.3s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 2/5; 11/12] END .activation_function=linear, init=normal; total time=   3.9s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 3/5; 11/12] END .activation_function=linear, init=normal; total time=   3.3s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 4/5; 11/12] END .activation_function=linear, init=normal; total time=   4.0s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 5/5; 11/12] END .activation_function=linear, init=normal; total time=   5.5s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 1/5; 12/12] END ...activation_function=linear, init=zero; total time=   4.6s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 2/5; 12/12] END ...activation_function=linear, init=zero; total time=   3.3s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 3/5; 12/12] END ...activation_function=linear, init=zero; total time=   3.3s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 4/5; 12/12] END ...activation_function=linear, init=zero; total time=   3.5s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 5/5; 12/12] END ...activation_function=linear, init=zero; total time=   4.3s\n"
     ]
    }
   ],
   "source": [
    "#### Tuning of Hyperparameters:- Activation Function and Kernel Initializer\n",
    "# Defining the model\n",
    "\n",
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 10,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 10,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.00033255736343562603, using {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.0,0.0 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.0,0.0 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.00033255736343562603,0.0006651147268712521 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.00033255736343562603,0.0006651147268712521 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.0,0.0 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END ......................neuron1=4, neuron2=2; total time=   3.6s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END ......................neuron1=4, neuron2=2; total time=   3.6s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END ......................neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END ......................neuron1=4, neuron2=2; total time=   3.7s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END ......................neuron1=4, neuron2=2; total time=   3.8s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END ......................neuron1=4, neuron2=4; total time=   3.5s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END ......................neuron1=4, neuron2=4; total time=   3.6s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END ......................neuron1=4, neuron2=4; total time=   3.6s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END ......................neuron1=4, neuron2=4; total time=   3.6s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END ......................neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END ......................neuron1=4, neuron2=8; total time=   5.2s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END ......................neuron1=4, neuron2=8; total time=   5.1s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END ......................neuron1=4, neuron2=8; total time=   4.7s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END ......................neuron1=4, neuron2=8; total time=   4.1s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END ......................neuron1=4, neuron2=8; total time=   3.6s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END ......................neuron1=8, neuron2=2; total time=   3.9s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END ......................neuron1=8, neuron2=2; total time=   3.8s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END ......................neuron1=8, neuron2=2; total time=   3.3s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END ......................neuron1=8, neuron2=2; total time=   3.3s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END ......................neuron1=8, neuron2=2; total time=   3.5s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END ......................neuron1=8, neuron2=4; total time=   3.5s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END ......................neuron1=8, neuron2=4; total time=   3.2s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END ......................neuron1=8, neuron2=4; total time=   3.4s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END ......................neuron1=8, neuron2=4; total time=   3.4s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END ......................neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END ......................neuron1=8, neuron2=8; total time=   5.3s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END ......................neuron1=8, neuron2=8; total time=   3.6s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END ......................neuron1=8, neuron2=8; total time=   3.4s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END ......................neuron1=8, neuron2=8; total time=   3.8s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END ......................neuron1=8, neuron2=8; total time=   3.7s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END .....................neuron1=16, neuron2=2; total time=   3.4s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END .....................neuron1=16, neuron2=2; total time=   3.3s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END .....................neuron1=16, neuron2=2; total time=   3.8s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END .....................neuron1=16, neuron2=2; total time=   3.5s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END .....................neuron1=16, neuron2=2; total time=   3.3s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END .....................neuron1=16, neuron2=4; total time=   3.3s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END .....................neuron1=16, neuron2=4; total time=   3.6s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END .....................neuron1=16, neuron2=4; total time=   3.6s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END .....................neuron1=16, neuron2=4; total time=   3.4s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END .....................neuron1=16, neuron2=4; total time=   3.6s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END .....................neuron1=16, neuron2=8; total time=   5.0s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END .....................neuron1=16, neuron2=8; total time=   5.7s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END .....................neuron1=16, neuron2=8; total time=   3.5s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END .....................neuron1=16, neuron2=8; total time=   3.5s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END .....................neuron1=16, neuron2=8; total time=   3.8s\n"
     ]
    }
   ],
   "source": [
    "#### Tuning of Hyperparameter :-Number of Neurons in activation layer\n",
    "# Defining the model\n",
    "\n",
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 10,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters all at once and this process will take more time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8748 candidates, totalling 43740 fits\n",
      "[CV 1/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2; total time=  12.0s\n",
      "[CV 2/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2; total time=  11.6s\n",
      "[CV 3/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2; total time=  11.1s\n",
      "[CV 4/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2; total time=  12.7s\n",
      "[CV 5/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2; total time=  13.7s\n",
      "[CV 1/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4; total time=  11.4s\n",
      "[CV 2/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4; total time=  11.0s\n",
      "[CV 3/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4; total time=  11.2s\n",
      "[CV 4/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4; total time=  14.4s\n",
      "[CV 5/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4; total time=  12.4s\n",
      "[CV 1/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 1/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8; total time=  12.1s\n",
      "[CV 2/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 2/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8; total time=  11.9s\n",
      "[CV 3/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 3/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8; total time=  15.2s\n",
      "[CV 4/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 4/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8; total time=  15.0s\n",
      "[CV 5/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
      "[CV 5/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8; total time=  12.2s\n",
      "[CV 1/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2; total time=  12.0s\n",
      "[CV 2/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2; total time=  12.0s\n",
      "[CV 3/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2; total time=  13.1s\n",
      "[CV 4/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2; total time=  13.2s\n",
      "[CV 5/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2; total time=  11.4s\n",
      "[CV 1/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4; total time=  12.0s\n",
      "[CV 2/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4; total time=  11.9s\n",
      "[CV 3/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4; total time=  16.1s\n",
      "[CV 4/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4; total time=  11.7s\n",
      "[CV 5/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4; total time=  11.3s\n",
      "[CV 1/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8; total time=  12.3s\n",
      "[CV 2/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 2/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8; total time=  14.5s\n",
      "[CV 3/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 3/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8; total time=  16.4s\n",
      "[CV 4/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 4/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8; total time=  12.4s\n",
      "[CV 5/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
      "[CV 5/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8; total time=  12.6s\n",
      "[CV 1/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 1/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2; total time=  14.0s\n",
      "[CV 2/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 2/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2; total time=  16.7s\n",
      "[CV 3/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 3/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2; total time=  14.1s\n",
      "[CV 4/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 4/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2; total time=  15.4s\n",
      "[CV 5/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
      "[CV 5/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2; total time=  13.7s\n",
      "[CV 1/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 1/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4; total time=  15.2s\n",
      "[CV 2/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 2/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4; total time=  13.0s\n",
      "[CV 3/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 3/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4; total time=  18.3s\n",
      "[CV 4/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 4/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4; total time=  16.4s\n",
      "[CV 5/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
      "[CV 5/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4; total time=  17.0s\n",
      "[CV 1/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 1/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8; total time=  12.8s\n",
      "[CV 2/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 2/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8; total time=  12.4s\n",
      "[CV 3/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 3/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8; total time=  13.4s\n",
      "[CV 4/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 4/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8; total time=  16.5s\n",
      "[CV 5/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
      "[CV 5/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8; total time=  12.2s\n",
      "[CV 1/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 1/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2; total time=  13.8s\n",
      "[CV 2/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
      "[CV 2/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2; total time=  15.2s\n",
      "[CV 3/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n"
     ]
    }
   ],
   "source": [
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 10,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n",
    "\n",
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
